[common]
# this location contains the yt_dlp archives, i.e. lists of already downloaded videos. It must be writeable
# by scrape23.
archivepath = "~/.scrape23/archives"

# This location contains the feeds generated by scrape23. It must writeable by the user scrape23 runs as and
# as it's where the webserver reads the feeds from, it must also be readable by the webserver. 
# 
# Scrape23 DOES NOT configure the server, nor does it impose any security restrictions, both are YOUR responsibility.
feeddir = "/var/www/html/feeds"

# This is the base URL visible to the podcast client where the feeds are served from.
feedurl = "https://yourserver/feeds/"

# yt-dlp rate limit. Can be overridden with --rate-limit or --ignore-rate-limit and is parsed by humanfriendly
# so you can use B for bytes and b for bits.
# Uncomment this if you want to ratelimit downloads for whatever reason.
#ratelimit = "500kB"

[feeds]

# Configure the feeds you want to generate here. The key is the a name of the feed that must be a valid name for
# files and directories as it is used to generate paths. The value is a table with the feedname and url keys.
# The feedname is the friendly name of the feed as it appears in the RSS feed, and the url is the URL 
# to the YouTube channel or search query.


[feeds."Viisasteluklubi"]
feedtitle = "Ivan Puopolo - Viisasteluklubi"
url = "https://www.youtube.com/@ivan_puopolo/videos"
# You can use a match string that is passed to yt-dlp for filtering episodes. See yt-dlp documentation for help.
match_title = "Viisastelu"
schedule = "5 12 * * 6"

[feeds."Kuuntelija"]
feedname = "Kuuntelija"
url = "https://www.youtube.com/@Kuuntelijapodcast/videos"
schedule = "5 12 * * 7"

[feeds."BetterOffline"]
feedname = "Better Offline"
url = "https://www.youtube.com/@BetterOfflinePod/videos"
schedule = "0 * * * *"

